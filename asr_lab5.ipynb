{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5  - WFST operations\n",
    "\n",
    "So far we've used WFSTs mainly as a usual structure for encoding and traversing HMMs.  In this lab we'll move away from HMM acoustic modelling and look at how WFST operations can be used to avoid the need for specialised algorithms in speech and language processing.  It is intended to give you insight into how these operations are used to construct HMMs encapsulating langauge model, pronunciation and acoustic modelling assumptions &ndash; the so-called \"HCLG\" WFST.\n",
    "\n",
    "This lab will focus on the lexicon transducer, $L$, and grammar transducer, $G$.\n",
    "\n",
    "We'll use some of the following operations, defined by Openpynini:\n",
    "* `pynini.determinize(f)` creates determinized version of `f`\n",
    "* `pynini.compose(f1,f2)` composes FSTs `f1` and `f2`\n",
    "* `pynini.shortestpath(f)` returns the shortest path (in terms of weight) through `f` from the start to a final state\n",
    "* `f.minimize()` creates minimized version of `f`\n",
    "* `f.project('output')` for every arc in `f`, copies the input label to the output label (or vice versa, if `'input'` is passed).\n",
    "* `f.rmepsilon()` removes epsilon transitions &ndash; those arcs where both input and output labels are empty.\n",
    "\n",
    "For efficiency, the compostion of `f1` and `f2` requires either the output arcs of `f1` or input arcs of `f2` to be sorted prior to `compose()` being called.  You can do this by calling `f1.arcsort(sort_type='olabel')` or `f2.arcsort(sort_type='ilabel')`.\n",
    "\n",
    "Combining projection and removal of epsilon transitions will give you better visual clarity when looking at your FSTS.\n",
    "\n",
    "The functions above assume that `pynini` has been imported.  Note that the first three functions above return a new WFST; the others modify the WFST *in place*, meaning that the original WFST is modified directly.\n",
    "\n",
    "For convenience, we've provided a python module `helper_functions` that provides the `parse_lexicon()` and `generate_symbol_tables()` from the [Lab 1 solutions](https://github.com/Ore-an/asr_lab1/blob/master/asr_lab1_solutions.ipynb).  And here is a function to generate an $L$ transducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynini\n",
    "from helper_functions import parse_lexicon, generate_symbol_tables\n",
    "\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)  # we won't use state_table in this lab\n",
    "eps = phone_table.find('<eps>')\n",
    "\n",
    "def generate_L_wpynini(lex):\n",
    "    \"\"\" Express the lexicon in WFST form\n",
    "    \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "    \n",
    "    Returns:\n",
    "        the constructed lexicon WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    L = pynini.Fst()\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = L.add_state()\n",
    "    L.set_start(start_state)\n",
    "    \n",
    "    for (word, pron) in lex.items():\n",
    "        \n",
    "        current_state = start_state\n",
    "        for (i,phone) in enumerate(pron):\n",
    "            next_state = L.add_state()\n",
    "            \n",
    "            if i == len(pron)-1:\n",
    "                # add word output symbol on the final arc\n",
    "                L.add_arc(current_state, pynini.Arc(phone_table.find(phone), \\\n",
    "                                                 word_table.find(word), None, next_state))\n",
    "            else:\n",
    "                L.add_arc(current_state, pynini.Arc(phone_table.find(phone),0, None, next_state))\n",
    "            \n",
    "            current_state = next_state\n",
    "                          \n",
    "        L.set_final(current_state)\n",
    "        \n",
    "    L.set_input_symbols(phone_table)\n",
    "    L.set_output_symbols(word_table)                      \n",
    "    \n",
    "    return L\n",
    "\n",
    "L = generate_L_wpynini(lex)\n",
    "L.arcsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the exercises, here are two functions to generate linear WFSTs for an arbitary sequence of phones or words.  (Yes, they are really just variants of the same function!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_phone_wpynini(phone_list):\n",
    "    \n",
    "    P = pynini.Fst()\n",
    "    \n",
    "    current_state = P.add_state()\n",
    "    P.set_start(current_state)\n",
    "    \n",
    "    for p in phone_list:\n",
    "        \n",
    "        next_state = P.add_state()\n",
    "        P.add_arc(current_state, pynini.Arc(phone_table.find(p), phone_table.find(p), None, next_state))\n",
    "        current_state = next_state\n",
    "        \n",
    "    P.set_final(current_state)\n",
    "    P.set_input_symbols(phone_table)\n",
    "    P.set_output_symbols(phone_table)\n",
    "    return P\n",
    "    \n",
    "def generate_linear_word_wpynini(word_list):\n",
    "    \n",
    "    W = pynini.Fst()\n",
    "    \n",
    "    current_state = W.add_state()\n",
    "    W.set_start(current_state)\n",
    "    \n",
    "    for w in word_list:\n",
    "        \n",
    "        next_state = W.add_state()\n",
    "        W.add_arc(current_state, pynini.Arc(word_table.find(w), word_table.find(w), None, next_state))\n",
    "        current_state = next_state\n",
    "        \n",
    "    W.set_final(current_state)\n",
    "    W.set_input_symbols(word_table)\n",
    "    W.set_output_symbols(word_table)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Suppose you are given a sequence of phones, in the form `['p','ih','k','t']`, and the $L$ transducer created above.  Write a function that returns the matching word from the lexicon for any given phone sequence, or else `None` if no matching word is found.   Write two functions:\n",
    "  1. That works for $L$ as provided by the code above\n",
    "  2. That works only on a determinized version of $L$ &ndash; and test it on the output of `pynini.determinize(L)`\n",
    "  \n",
    " This should enable you to see why determinization is a very useful WFST operation!\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def transduce_sequence_nondet(f, in_seq):\n",
    "    \"\"\"Return transduced sequence given input sequence and non determinized FST.\n",
    "        Note that our skeleton code uses a queue to traverse the FST.\n",
    "        You can change this if you prefer, as long as you correctly output the list of trasduced words.\n",
    "    \n",
    "        Args:\n",
    "            f (pynini.Fst()): a non determinized FST\n",
    "            in_seq (list[str]): the sequence of strings to transduce\n",
    "            \n",
    "        Returns:\n",
    "            out_seq (list[str]): the sequence of transduced symbols\n",
    "            \"\"\"\n",
    "    \n",
    "    seq_len = len(in_seq)\n",
    "    in_seq.append('<EOS>') # adding a padding symbol at the end for possible final eps traversal\n",
    "    queue = [(f.start(), 0, [])]  # the tuple is (state, index in input sequence, output)\n",
    "    outputs = []\n",
    "    \n",
    "    while queue:\n",
    "        curr_state, i, output = queue.pop(0) # pop first element in list\n",
    "        \n",
    "        if i <= seq_len:  # <= because we could traverse epsilons even when the input sequence ended\n",
    "            \n",
    "            # Your code here\n",
    "            \n",
    "        if i == seq_len:\n",
    "            final_weight = float(f.final(curr_state))\n",
    "            if final_weight != math.inf: # if this is a final state\n",
    "                out_seq = [f.output_symbols().find(w) for w in output if w != eps]  # find the labels in the table, remove epsilons\n",
    "                return out_seq\n",
    "            \n",
    "        \n",
    "    print(\"Can't transduce the sequence with provided FST\")  # return exits the function, so this is printed only when the stack is empty and we didn't find a path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['p','ih','k','t']\n",
    "print(transduce_sequence_nondet(L, seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You should see the result below after running the last block\n",
    "# ['picked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transduce_sequence_det(f, seq):\n",
    "    \"\"\"Return transduced sequence given input sequence and determinized FST\n",
    "    \n",
    "        Args:\n",
    "            f (pynini.Fst()): a determinized FST\n",
    "            in_seq (list[str]): the sequence of strings to transduce\n",
    "            \n",
    "        Returns:\n",
    "            out_seq (list[str]): the sequence of transduced symbols\n",
    "            \"\"\"\n",
    "    \n",
    "    seq_len = len(seq)\n",
    "    curr_state = f.start()\n",
    "    output = []\n",
    "    \n",
    "    for i in range(seq_len):\n",
    "        # Your code here\n",
    "    final_weight = float(f.final(curr_state))\n",
    "    if final_weight != math.inf: # if this is a final state\n",
    "        out_seq = [f.output_symbols().find(w) for w in output if w != eps]  # find the labels in the table, remove epsilons\n",
    "        return out_seq\n",
    "    else:  \n",
    "        print(\"Can't transduce the sequence with provided FST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['p','ih','k','t']\n",
    "Ldet = pynini.determinize(L)\n",
    "print(transduce_sequence_det(Ldet, seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should see the result below after running the last block\n",
    "# ['picked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. WFST composition allows you to achieve the same result much more easily.  Create a linear WFST, $P$, corresponding to a string of phones, and compute $P \\circ L$.  Then use the projection and epsilon removal operations to display just the matching word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['p','ih','k','t']\n",
    "P = generate_linear_phone_wpynini(seq)\n",
    "\n",
    "def compose_phone_sequence_with_lexicon(P, L):\n",
    "\n",
    "    # Your code here for composition of P and L and other necessary FST operations\n",
    "    \n",
    "    return comp\n",
    "\n",
    "comp = compose_phone_sequence_with_lexicon(P, L)\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![compose_phone_sequence_with_lexicon](figs/compose_phone_sequence_with_lexicon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modify your lexicon WFST slightly to allow a list of phones to be \"decoded\" to a sequence of multiple words from the lexicon. Then, compose the modified lexicon with a sequence of phones of multiple concatenated words.  Try it with `['p','eh','k','ah','v','p','iy','t','er']`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this modified the Lexicon WFST directly - you can also do it by adding\n",
    "# extra code to the generate_L_wpynini() function above\n",
    "# The code below enables L to decode a sequence of phones corresponding to multiple words\n",
    "\n",
    "start_state = L.start()\n",
    "for state in L.states():\n",
    "    if float(L.final(state)) != math.inf:\n",
    "        L.add_arc(state, pynini.Arc(0, 0, None, start_state))  # add arc to start\n",
    "Ldet = pynini.determinize(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['p','eh','k','ah','v','p','iy','t','er']\n",
    "P = generate_linear_phone_wpynini(seq)\n",
    "\n",
    "def compose_phone_sequences_with_lexicon(P, L):\n",
    "    \n",
    "\n",
    "    # Your code here for composition of P and L and other necessary FST operations\n",
    "    \n",
    "    return comp\n",
    "\n",
    "comp = compose_phone_sequences_with_lexicon(P, L)\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![compose_phone_sequences_with_lexicon](figs/compose_phone_sequences_with_lexicon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now solve the reverse problem: create a word-sequence WFST, $W$, and use composition to expand it into a sequence of phones. You'll need to sort by output labels this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['peck', 'of', 'peter']\n",
    "W = generate_linear_word_wpynini(seq)\n",
    "\n",
    "def compose_lexicon_with_word_sequence(L, W):\n",
    "    \n",
    "    # Your code here\n",
    "    return comp\n",
    "\n",
    "comp = compose_lexicon_with_word_sequence(L, W)\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![compose_lexicon_with_word_sequence](figs/compose_lexicon_with_word_sequence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Another advantage of WFST composition to solve these kind of problems are that it is easy to encode uncertainty in the input (a bit like in real ASR).  For example, consider this WFST, in which the multiple arcs denote alternative phone transcriptions from the acoustic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alt_phone_wpynini(phone_alternatives):\n",
    "    \n",
    "    P = pynini.Fst()\n",
    "    \n",
    "    current_state = P.add_state()\n",
    "    P.set_start(current_state)\n",
    "    \n",
    "    for alt in phone_alternatives:\n",
    "        \n",
    "        next_state = P.add_state()\n",
    "        for p in alt:\n",
    "            if p=='*':\n",
    "                P.set_final(current_state)\n",
    "            else:\n",
    "                P.add_arc(current_state, pynini.Arc(phone_table.find(p), phone_table.find(p), None, next_state))\n",
    "        current_state = next_state\n",
    "        \n",
    "    P.set_final(current_state)\n",
    "    P.set_input_symbols(phone_table)\n",
    "    P.set_output_symbols(phone_table)\n",
    "    return P    \n",
    "    \n",
    "altP = create_alt_phone_wpynini([['p'],['ay'],['p'],['er'],['p'],['eh','ih'],['k'],['t','<eps>'],['ah','<eps>'],['l','v','*'],['d','*']])\n",
    "altP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Again, perform composition with your $L$ from Question 3, and observe the result.  (Notice particularly what happens to the `<eps>` transitions during composition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altP.arcsort()\n",
    "comp = # Please compose altP and L here \n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![compose_altP_lexicon](figs/compose_altP_lexicon.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainP = # Please project the output labels and remove epsilons here \n",
    "uncertainP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![project_output.png](figs/project_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We could have added weights to the arcs of the WFST above to describe the probability of the phone alternatives given by the acoustic model &ndash; this would have enabled you to find the most likely sequence of words.  Without this information, let's instead use a $G$ WFST to find the most likely sequence.  Let's assume that a word sequence taken from the passage \"peter piper picked a peck of pickled peppers\" is most likely.  Design a $G$ WFST that accepts any sequence of words from the lexicon, but adds a cost of 1.0 to any word transition not in the passage.  Given $G$, use composition to recover the most likely word sequence from the uncertain $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_G_wpynini(wseq):\n",
    "    \"\"\" Generate a grammar WFST that accepts any sequence of words for words in a sentence.\n",
    "        Word transitions not present in the sentence have a cost of 1, while those present have a cost of 0. \n",
    "        Args:\n",
    "            wseq (str): the sentence to use\n",
    "        Returns:\n",
    "            W (pynini.Fst()): the grammar WFST \"\"\"\n",
    "    \n",
    "    G = pynini.Fst()\n",
    "    start_state = G.add_state()\n",
    "    G.set_start(start_state)\n",
    "    \n",
    "    prev_state = None\n",
    "    \n",
    "    for w in wseq.split():\n",
    "        current_state = G.add_state()\n",
    "\n",
    "        # Your code here\n",
    "    \n",
    "    G.set_final(start_state)\n",
    "        \n",
    "    G.set_input_symbols(word_table)\n",
    "    G.set_output_symbols(word_table)  \n",
    " \n",
    "    return G\n",
    "\n",
    "string = \"peter piper picked a peck of pickled peppers\"\n",
    "G = generate_G_wpynini(string)\n",
    "G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the composition of the alternative pronunciation sequence and L you did in the exercise before and compose it with your new grammar. Check the output of the shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composition with your G wpynini\n",
    "\n",
    "G.arcsort(sort_type='olabel')\n",
    "comp = pynini.compose(uncertainP, G)\n",
    "comp.rmepsilon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something similar to this\n",
    "![compose_with_G](figs/compose_with_G.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your result\n",
    "pynini.shortestpath(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this figure after running the last block\n",
    "![results.png](figs/results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use WFST composition to implement a \"predictive text\"-style algorithm, that, given a partial phone sequence such as `['p']` or `['p','ih']`, returns a WFST giving all matching words.  You'll need to make some special modifications to $P$ or $L$, or both. On a determinized $L$ transducer this is a highly efficient way of solving this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are very many ways this problem can be solved. Our skeleton code add extra arcs with \n",
    "# special <rho> symbol. This symbol will represent unterminated sequences, and will be transduced\n",
    "#  to words to be output at every intermediate state.\n",
    "# The same <rho> symbol is added the end of the partial pronunciation.\n",
    "\n",
    "def generate_predictive_L_wpynini(lex):\n",
    "    \"\"\" express the lexicon in WFST form s.t. composition with partial sequence gives matching words\n",
    "    \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "    \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    Lpred = pynini.Fst()\n",
    "    rho = phone_table.add_symbol('<rho>')\n",
    "    # create a single start state\n",
    "    start_state = Lpred.add_state()\n",
    "    Lpred.set_start(start_state)\n",
    "    \n",
    "    for (word, pron) in lex.items():\n",
    "        \n",
    "        # Your code here\n",
    "        \n",
    "    Lpred.set_input_symbols(phone_table)\n",
    "    Lpred.set_output_symbols(word_table)                      \n",
    "    \n",
    "    return Lpred\n",
    "\n",
    "Lpred = generate_predictive_L_wpynini(lex)\n",
    "Lpred.arcsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['p']\n",
    "seq += ['<rho>']\n",
    "Ppred = generate_linear_phone_wpynini(seq)\n",
    "Ppred.arcsort(sort_type='ilabel')\n",
    "comp = pynini.compose(Ppred, Lpred)\n",
    "comp.project('output').rmepsilon()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
